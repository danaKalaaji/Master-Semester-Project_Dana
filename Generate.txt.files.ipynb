{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba39391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import soundfile as sf\n",
    "from scipy.signal import resample_poly\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1186d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenarios():\n",
    "    scenarios = [\n",
    "        (\"healthy\", \"male\", \"healthy\", \"male\"),\n",
    "        (\"healthy\", \"male\", \"healthy\", \"female\"),\n",
    "        (\"healthy\", \"female\", \"healthy\", \"female\"),\n",
    "        (\"sick\", \"male\", \"sick\", \"male\"),\n",
    "        (\"sick\", \"male\", \"sick\", \"female\"),\n",
    "        (\"sick\", \"female\", \"sick\", \"female\"),\n",
    "        (\"healthy\", \"male\", \"sick\", \"male\"),\n",
    "        (\"healthy\", \"male\", \"sick\", \"female\"),\n",
    "        (\"healthy\", \"female\", \"sick\", \"male\"),\n",
    "        (\"healthy\", \"female\", \"sick\", \"female\"),\n",
    "    ]\n",
    "    return scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2088a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Returns a dictionnary audio_paths with all the audio paths in the directory base_dir for each scenario (health, gender)\n",
    "Uses the dataframe df to find the gender of the speaker of an audio\n",
    "'''\n",
    "\n",
    "def get_audio_paths(base_dir, df):\n",
    "    audio_paths = {}\n",
    "\n",
    "    # Iterate through all the audio files in the directory\n",
    "    for root, _ , files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                audio_path = os.path.join(root, file)\n",
    "\n",
    "                # Find the row in the dataframe that matches the ID of the audio file\n",
    "                id = file.split(\"_\")[0]\n",
    "                matching_row = df[df['RECODING ORIGINAL NAME'] == id]   \n",
    "                \n",
    "                if len(matching_row) == 1:\n",
    "                    # Find if the ID corresponds to a male of a female\n",
    "                    gender_letter = matching_row['SEX'].item()  \n",
    "                    gender = \"male\" if gender_letter == \"M\" else \"female\" if gender_letter == \"F\" else None\n",
    "                    if gender is None:\n",
    "                            raise ValueError(f\"Invalid gender: {gender_letter}\")\n",
    "                    \n",
    "                    # Find if the ID corresponds to a healthy or a sick person\n",
    "                    health_condition = \"healthy\" if \"hc\" in root or \"HC\" in root else \"sick\" if \"pd\" in root or \"PD\" in root else None \n",
    "                    if health_condition is None:\n",
    "                        raise ValueError(f\"Invalid health condition for {audio_path}\")\n",
    "                    \n",
    "                    # Add the audio path to the dictionary\n",
    "                    key = (health_condition, gender)\n",
    "                    if key not in audio_paths:\n",
    "                        audio_paths[key] = []\n",
    "                    audio_paths[key].append(audio_path)\n",
    "                \n",
    "                # If there is no matching row or more than one matching row, raise an error       \n",
    "                else:\n",
    "                    if  matching_row.empty:\n",
    "                        raise ValueError(f\"No matching rows found for ID: {id}, found in {audio_path} \")\n",
    "                    else:\n",
    "                        raise ValueError(f\"Expected 1 matching row for ID: {id}, but found more.\")\n",
    "    \n",
    "    # Print the number of audio paths for each key\n",
    "    for key, audio_list in audio_paths.items():\n",
    "        print(f\"Key: {key}, Number of Audio Paths: {len(audio_list)}\")\n",
    "    \n",
    "    return audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f027ebd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Creates the directory text_file_dir and the text files for all possible combinations of audio files\n",
    "Creates the directory processed_audio_dir and the text files for the processed audio files\n",
    "'''\n",
    "def create_text_files(text_file_dir, processed_audio_dir, audio_paths, scenarios):\n",
    "    # Create the text_file directory if it does not exist\n",
    "    if not os.path.exists(text_file_dir):\n",
    "        os.makedirs(text_file_dir)\n",
    "    \n",
    "    # Create the processed_audio directory if it does not exist\n",
    "    if not os.path.exists(processed_audio_dir):\n",
    "        os.makedirs(processed_audio_dir)\n",
    "\n",
    "    # Create an output file for each scenario\n",
    "    for scenario in scenarios:\n",
    "        condition1, gender1, condition2, gender2 = scenario\n",
    "        output_filename = f\"{condition1}_{gender1}_vs_{condition2}_{gender2}.txt\"\n",
    "        output_path = os.path.join(text_file_dir, output_filename)\n",
    "\n",
    "        # Create the sub_processed_audio directory if it does not exist\n",
    "        output_sub_dir = os.path.splitext(output_filename)[0]   #removes the .txt extension\n",
    "        sub_processed_audio_dir = os.path.join(processed_audio_dir, output_sub_dir)\n",
    "        if not os.path.exists(sub_processed_audio_dir):\n",
    "            os.makedirs(sub_processed_audio_dir)\n",
    "\n",
    "        # Create the empty text files in processed_audio_dir for each scenario  \n",
    "        output_path_processed = os.path.join(sub_processed_audio_dir, output_filename)\n",
    "        with open(output_path_processed, \"w\") as output_file:\n",
    "            pass\n",
    "        \n",
    "        # Create the text files in text_file_dir for each scenario and fills them\n",
    "        with open(output_path, \"w\") as output_file:\n",
    "            audio_group_1 = audio_paths[(condition1, gender1)]\n",
    "            audio_group_2 = audio_paths[(condition2, gender2)]\n",
    "            alpha, beta, SNR, duration = np.nan, np.nan, np.nan, np.nan\n",
    "            written_pairs = set()\n",
    "\n",
    "            # Iterate through all combinations of audio files\n",
    "            for audio1 in audio_group_1:\n",
    "                for audio2 in audio_group_2:\n",
    "                    # Get the ID and sentence of each audio file\n",
    "                    id1 = os.path.basename(audio1).split(\"_\")[0]\n",
    "                    id2 = os.path.basename(audio2).split(\"_\")[0]\n",
    "                    sentence1 = os.path.basename(audio1).split(\"_\")[1]\n",
    "                    sentence2 = os.path.basename(audio2).split(\"_\")[1]\n",
    "\n",
    "                    # If the audio files are not the same and the sentences are not the same\n",
    "                    if id1 != id2 and sentence1 != sentence2:\n",
    "                        # In this case the pair (audio1, audio2) == (audio2, audio1)\n",
    "                        if (condition1, gender1) == (condition2, gender2):\n",
    "                            # If the audio files are not already written to the file\n",
    "                            if (audio1, audio2) not in written_pairs and (audio2, audio1) not in written_pairs:\n",
    "                                output_file.write(f\"{audio1} {alpha} {audio2} {SNR} {beta} {duration}\\n\")\n",
    "                                written_pairs.add((audio1, audio2))\n",
    "                        else:\n",
    "                            output_file.write(f\"{audio1} {alpha} {audio2} {beta} {SNR} {duration}\\n\")\n",
    "                            \n",
    "                        \n",
    "        # Count the number of lines in the file\n",
    "        with open(output_path, \"r\") as output_file:\n",
    "            number_of_lines = sum(1 for line in output_file)\n",
    "        print(f\"Number of lines in {output_filename}: {number_of_lines}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "885d31aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Downsamples all the audios signals with path contained in audio_paths at the target_sample_rate\n",
    "'''\n",
    "def downsample_audio(audio_paths, target_sample_rate):\n",
    "    # Iterate through all the audio files in the directory\n",
    "    for key, paths in audio_paths.items():\n",
    "        for audio_path in paths:\n",
    "            audio, sr = sf.read(audio_path)\n",
    "            audio = resample_poly(audio, target_sample_rate, sr)    # Downsample the audio file\n",
    "            sf.write(audio_path, audio, target_sample_rate)         # Overwrite original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes the weight alpha and beta of audio1 and audio2 respectively used to generate the mix audio signal\n",
    "'''\n",
    "def calculate_audio_values(audio1, audio2):\n",
    "    \n",
    "    # Load the audio files\n",
    "    audio1, sr1 = sf.read(audio1)\n",
    "    audio2, sr2 = sf.read(audio2)\n",
    "\n",
    "   # Ensure both audio signals have the same length\n",
    "    duration = min(len(audio1), len(audio2))\n",
    "    audio1 = audio1[:duration]\n",
    "    audio2 = audio2[:duration]\n",
    "    \n",
    "    # Normalize the audio signals\n",
    "    lev1 = np.mean(np.square(audio1))\n",
    "    lev2 = np.mean(np.square(audio2))\n",
    "    audio1 /= np.sqrt(lev1)\n",
    "    audio2 /= np.sqrt(lev2)\n",
    "\n",
    "    # Generate a random SNR between 0 and 5 dB and calculate weights\n",
    "    SNR = random.uniform(0, 5)\n",
    "    alpha_temp = 10 ** (SNR/20)\n",
    "    beta_temp = 10 ** (-SNR/20)\n",
    "   \n",
    "    # Apply weights\n",
    "    audio1 *= alpha_temp\n",
    "    audio2 *= beta_temp\n",
    "\n",
    "    # Calculate the maximum amplitude and scale the signals\n",
    "    mix_audio = audio1 + audio2\n",
    "    max_amp = max(np.max(np.abs(mix_audio)), np.max(np.abs(audio1)), np.max(np.abs(audio2)))\n",
    "    scaling_factor = 0.9 / max_amp\n",
    "    \n",
    "    audio1 *= scaling_factor\n",
    "    audio2 *= scaling_factor\n",
    "    #mix_audio *= scaling_factor\n",
    "\n",
    "    # Calculate the final weights values\n",
    "    alpha = alpha_temp * (scaling_factor/ np.sqrt(lev1))\n",
    "    beta = beta_temp * (scaling_factor/ np.sqrt(lev2))\n",
    "\n",
    "    return alpha, beta, SNR, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Computes new values of audio1, alpha, audio2, beta, SNR, duration  for each scenario \n",
    "Updates the corresponding text file found in text_file_dir with these new values\n",
    "'''\n",
    "def update_text_files(text_file_dir):    \n",
    "    # Iterate through all the text files in the directory\n",
    "    for filename in os.listdir(text_file_dir):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            text_file_path = os.path.join(text_file_dir, filename)\n",
    "            print(f\"Updating {filename}\")\n",
    "            \n",
    "            # Update the values of each line in the text file\n",
    "            with open(text_file_path, \"r\") as text_file:\n",
    "                lines = text_file.readlines()\n",
    "                updated_lines = []\n",
    "                for line in lines:\n",
    "                    audio1, alpha, audio2, beta, SNR, duration = line.split()\n",
    "                    new_alpha, new_beta, new_SNR, new_duration = calculate_audio_values(audio1, audio2)\n",
    "                    line = f\"{audio1} {new_alpha} {audio2} {new_beta} {new_SNR} {new_duration}\\n\"\n",
    "                    updated_lines.append(line)\n",
    "            # Update the text file\n",
    "            with open(text_file_path, 'w') as text_file:\n",
    "                text_file.writelines(updated_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "066f9235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: ('healthy', 'female'), Number of Audio Paths: 250\n",
      "Key: ('healthy', 'male'), Number of Audio Paths: 250\n",
      "Key: ('sick', 'male'), Number of Audio Paths: 250\n",
      "Key: ('sick', 'female'), Number of Audio Paths: 250\n"
     ]
    }
   ],
   "source": [
    "base_dir = r\"PC-GITA_per_task_16000Hz\" \n",
    "text_file_dir = os.path.join(base_dir, \"text_files\")\n",
    "processed_audio_dir = os.path.join(base_dir, \"processed_audio\")\n",
    "excel_file_path = excel_file_path = os.path.join(base_dir, \"PCGITA_allmetadata.xlsx\")\n",
    "\n",
    "df = pd.read_excel(excel_file_path, sheet_name='PD+HC', usecols=['RECODING ORIGINAL NAME', 'SEX'])\n",
    "\n",
    "target_sample_rate = 8000\n",
    "scenarios = generate_scenarios()\n",
    "audio_paths = get_audio_paths(base_dir, df)\n",
    "\n",
    "#create_text_files(text_file_dir, processed_audio_dir, audio_paths, scenarios)\n",
    "#downsample_audio(audio_paths, target_sample_rate)\n",
    "#update_text_files(text_file_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
